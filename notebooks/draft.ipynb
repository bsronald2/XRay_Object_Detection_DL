{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ronald/PycharmProjects/x-ray-deep-learning/X-ray_Object_Detection\n",
      "Images Path: data/raw/images\n",
      "Annotation Path: data/raw/annotation\n"
     ]
    }
   ],
   "source": [
    "# Set in root_directory\n",
    "%cd /home/ronald/PycharmProjects/x-ray-deep-learning/X-ray_Object_Detection/\n",
    "#%ls    \n",
    "# libs \n",
    "import numpy as np    \n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# Directories\n",
    "ROOT = Path('data/raw')\n",
    "images_path = ROOT / 'images'\n",
    "ann_path = ROOT/ 'annotation'\n",
    "print('Images Path:', images_path)\n",
    "print('Annotation Path:', ann_path)\n",
    "\n",
    "# Labels/n_classes\n",
    "labels = ['gun'] #, 'knife', 'shuriken', 'razor_blade']\n",
    "n_classes = len(labels) + 1 # count background\n",
    "\n",
    "# Image Dimenssions\n",
    "dim = (256, 256, 1)\n",
    "\n",
    "# Collect all files absolute Path \n",
    "imgs_paths = sorted([i.absolute() for i in images_path.glob(\"*.png\") if i.is_file()])\n",
    "\n",
    "indexes = np.arange(len(imgs_paths))\n",
    "\n",
    "batch_size = 4\n",
    "index = 15\n",
    "# Set batch indexes\n",
    "# if index 0 and batch 4 in range(0, 17) retrieve values [0 1 2 3]\n",
    "# if index 1 and batch 4 in range(0, 17) retrieve values [4 5 6 7]\n",
    "#indexes = indexes[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "#imgs_paths = [imgs_paths[index] for index in indexes]\n",
    "imgs_name = [img.name for img in imgs_paths]\n",
    "\n",
    "# Create empty data-set.\n",
    "X = np.empty((batch_size, *dim), dtype=np.float32)\n",
    "y = np.empty((batch_size, dim[0], dim[1], n_classes), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open imgs annotations\n",
    "with open(\"data/raw/annotation/coco_annotation.json\", \"r\") as read_it: \n",
    "     ann_data = json.load(read_it)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "dict_imgs = ann_data.get('images')\n",
    "dict_ann = ann_data.get('annotations')\n",
    "dict_cat = ann_data.get('categories')\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),# horizontal flips\n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    iaa.GaussianBlur(sigma=(0, 0.5)), \n",
    "    # Crop image with random from 0 to 10%    \n",
    "    # But we only crop about 50% of all images.\n",
    "    iaa.Sometimes(\n",
    "        0.5,\n",
    "       iaa.Crop(percent=(0, 0.1), keep_size=True)),\n",
    "    # Strengthen or weaken the contrast in each images.\n",
    "    iaa.LinearContrast((0.75, 1)),\n",
    "\n",
    "    # Add gaussian noise.\n",
    "    # For 30% of all images, we sample the noise once per pixel.\n",
    "    # For the other 30% of all images, we sample the noise per pixel AND\n",
    "    # channel. This can change the color (not only brightness) of the\n",
    "    # pixels.\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05), per_channel=0.3),\n",
    "\n",
    "    # Apply affine transformations to each images.\n",
    "    # Scale/zoom them.\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (1.0, 1.1), \"y\": (1.0, 1.1)})\n",
    "], random_order=True) # apply augmenters in random order\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n",
      "(256, 256, 1)\n",
      "(256, 256, 1)\n",
      "(256, 256, 1)\n",
      "(256, 256, 1)\n",
      "(256, 256, 1)\n",
      "(256, 256, 1)\n",
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "def search_array(array, key, value):\n",
    "    return next((obj for obj in array if obj[key] == value), None) # return object\n",
    "\n",
    "def get_img_seg_kps(img_seg):\n",
    "    points = list()\n",
    "    for i in range(0, len(img_seg), 2): # iterate every two steps\n",
    "        chunk = img_seg[i:i+2]\n",
    "        points.append(Keypoint(x=chunk[0], y=chunk[1]))\n",
    "    \n",
    "    return points\n",
    "\n",
    "def get_img_info(img_name):\n",
    "    \"\"\"\n",
    "    return img_label and segmentation points of the image\n",
    "    \"\"\"\n",
    "    img_seg, label = None, None\n",
    "    img_obj = search_array(dict_imgs, 'file_name', img_name)\n",
    "    if img_obj is not None:\n",
    "        ann_obj = search_array(dict_ann, 'image_id', str(img_obj['id']))\n",
    "        if ann_obj is not None:\n",
    "            kps = get_img_seg_kps(ann_obj['segmentation'])\n",
    "            label = search_array(dict_cat, 'id', ann_obj['category_id'])\n",
    "            return label['name'], kps\n",
    "        else: # Create annotation for image\n",
    "            kps = create_img_seg(img_obj)\n",
    "            return 'background', kps\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_img_seg(img_obj):\n",
    "    height = img_obj['height']\n",
    "    width = img_obj['width']\n",
    "    points = [\n",
    "        Keypoint(x=0, y=0),\n",
    "        Keypoint(x=width-1, y=0),\n",
    "        Keypoint(x=width-1, y=height-1),\n",
    "        Keypoint(x=0, y=height-1)\n",
    "    ]\n",
    "#    print(points)\n",
    "    return points\n",
    "\n",
    "def get_augimg(img, img_info):\n",
    "    label, points = img_info\n",
    "    kps = KeypointsOnImage(points, shape=img.shape)\n",
    "    if img.shape != dim:\n",
    "        img = ia.imresize_single_image(img, dim[0:2])\n",
    "        kps = kps.on(img)\n",
    "    # Augment keypoints and images.\n",
    "    seq_det = seq.to_deterministic()\n",
    "    img_aug = seq_det.augment_images([img])[0]\n",
    "    kps_aug = seq_det.augment_keypoints([kps])[0]\n",
    "#     print(kps)\n",
    "#     print(\"--------\\n\", kps_aug)\n",
    "#     img_aug, kps_aug = seq(image=img, keypoints=kps)\n",
    "    aug_points = [[kp.x, kp.y] for kp in kps_aug.keypoints]\n",
    "    aug_points_dic = {'label': label, 'points': aug_points}\n",
    "#     ia.imshow(np.hstack([\n",
    "#         kps.draw_on_image(img, size=10),\n",
    "#         kps_aug.draw_on_image(img_aug, size=10)]))\n",
    "\n",
    "    return img_aug, aug_points_dic\n",
    "    \n",
    "def show(img):\n",
    "    print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()\n",
    "\n",
    "def get_mask(img, imgaug_shape):\n",
    "    blank = np.zeros(shape=(img.shape[0], img.shape[1]), dtype=np.float32)\n",
    "    points = np.array(imgaug_shape['points'], dtype=np.int32)\n",
    "    label = imgaug_shape['label']\n",
    "    cv2.fillPoly(blank, [points], 255)\n",
    "    blank = blank / 255.0\n",
    "#     ia.imshow(img)\n",
    "#     ia.imshow(blank)\n",
    "    return np.expand_dims(blank, axis=2)\n",
    "\n",
    "    \n",
    "def data_generation(img_path):\n",
    "    X = np.empty((batch_size, *dim), dtype=np.float32)\n",
    "    y = np.empty((batch_size, dim[0], dim[1], n_classes), dtype=np.float32)    \n",
    "    \n",
    "    # retrieve img in gray_scale as numpy\n",
    "    img = cv2.imread(str(img_path), 0) # our images are gray_scale\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "#     img = (img / 255.0).astype(np.float32)\n",
    "    images = [np.copy(img) for _ in range(batch_size)]\n",
    "    img_info = get_img_info(img_path.name)\n",
    "    for i, image in enumerate(images):\n",
    "        imgaug, imgaug_shape = get_augimg(img, img_info)\n",
    "        imgaug_mask = get_mask(imgaug, imgaug_shape)\n",
    "        print(imgaug.shape)\n",
    "        print(imgaug_mask.shape)\n",
    "        X[i,] = imgaug\n",
    "        y[i,] = imgaug_mask\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "img_pol = data_generation(imgs_paths[index])\n",
    "#print(img_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
